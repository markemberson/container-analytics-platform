version: '3.9'

x-superset-image: &superset-image apache/superset:2.0.0
x-superset-depends-on: &superset-depends-on
  - postgres
  - redis
x-superset-volumes: &superset-volumes
  # /app/pythonpath_docker will be appended to the PYTHONPATH in the final container
  - ./superset/docker:/app/docker
  - ./superset/config.py:/app/superset/config.py
  - superset_home:/app/superset_home

services:
  jupyter:
    build: ./jupyter/
    environment:
      - S3_ENDPOINT=http://minio:9000
      - S3_BUCKET=test
      - S3_ACCESS_KEY=sparkaccesskey
      - S3_SECRET_KEY=sparksupersecretkey
    ports: 
      - 8888:8888
    volumes:
      - ./data:/data
      - ./jupyter/notebooks/:/notebooks/
  postgres:
    image: postgres:14
    environment:
      - POSTGRES_USER=hive
      - POSTGRES_PASSWORD=hive
      - POSTGRES_DB=metadata
    volumes:
      - postgres-db:/var/lib/postgresql/data
      - ./superset/init_supersetdb.sql:/docker-entrypoint-initdb.d/init_supersetdb.sql
    healthcheck:
      test: ["CMD", "pg_isready","-U", "hive", "metadata"]
    restart: always
  metastore:
    build: ./metastore
    # volumes:
    #   - hive-data:/opt/warehouse # /user/hive/warehouse is where hive standalone metastore keeps data
    ports:
      - 9083:9083 #Thrift port
    depends_on:
      - postgres
      - minio
  minio:
    image: quay.io/minio/minio
    command: ["server", "/data", "--console-address", ":9090"]
    environment:
      - MINIO_ROOT_USER=minio
      - MINIO_ROOT_PASSWORD=minio123
    volumes:
      - minio-data:/data
    ports:
      - 9090:9090
      - 9000:9000
  minio-init:
    build: ./minio # MinioClient image; use it to make buckets and perform any other tasks on startup
    depends_on:
      - minio
  trino:
    build: ./trino
    ports:
      - 8880:8080

  aws:
    image: amazon/aws-cli

  superset:
    env_file: superset/docker/.env-non-dev
    image: *superset-image
    command: ["/app/docker/docker-bootstrap.sh", "app-gunicorn"]
    user: "root"
    restart: unless-stopped
    ports:
      - 8088:8088
    depends_on: *superset-depends-on
    volumes: *superset-volumes
  superset-init:
    image: *superset-image
    command: ["/app/docker/docker-init.sh"]
    env_file: superset/docker/.env-non-dev
    depends_on: *superset-depends-on
    user: "root"
    volumes: *superset-volumes
  superset-worker:
    image: *superset-image
    command: ["/app/docker/docker-bootstrap.sh", "worker"]
    env_file: superset/docker/.env-non-dev
    restart: unless-stopped
    depends_on: *superset-depends-on
    user: "root"
    volumes: *superset-volumes
  superset-worker-beat:
    image: *superset-image
    command: ["/app/docker/docker-bootstrap.sh", "beat"]
    env_file: superset/docker/.env-non-dev
    restart: unless-stopped
    depends_on: *superset-depends-on
    user: "root"
    volumes: *superset-volumes
  redis:
    image: redis:latest
    restart: unless-stopped
    volumes:
      - redis:/data
  spark:
    build: ./spark
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    ports:
      - '8090:8080'
      - '7077:7077'
    volumes:
      - ./data:/data
  spark-worker:
    build: ./spark
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark:7077
      - SPARK_WORKER_MEMORY=1G
      - SPARK_WORKER_CORES=1
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    volumes:
      - ./data:/data
  
  # mongo:
  #   image: mongo:6.0
  #   restart: unless-stopped
  #   environment:
  #     MONGO_INITDB_DATABASE: mongo
  #     MONGO_INITDB_ROOT_USERNAME: root
  #     MONGO_INITDB_ROOT_PASSWORD: example
  #   ports:
  #     - 27017:27017
  #   volumes:
  #     - mongo_data:/data/db
  
  # elasticsearch:
  #   image: docker.elastic.co/elasticsearch/elasticsearch:7.17.0
  #   environment:
  #     - "ES_JAVA_OPTS=-Xms1024m -Xmx2g"
  #     - discovery.type=single-node
  #   ulimits:
  #     memlock:
  #       soft: -1
  #       hard: -1
  #   volumes:
  #     - elasticsearch_data:/usr/share/elasticsearch/data
  #   ports:
  #     - 9200:9200

  ## All services below are for Datahub
  broker:
    container_name: broker
    depends_on:
      - zookeeper
    environment:
      - KAFKA_BROKER_ID=1
      - KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181
      - KAFKA_LISTENER_SECURITY_PROTOCOL_MAP=PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      - KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://broker:29092,PLAINTEXT_HOST://localhost:9092
      - KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR=1
      - KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS=0
      - KAFKA_HEAP_OPTS=-Xms256m -Xmx256m
      - KAFKA_CONFLUENT_SUPPORT_METRICS_ENABLE=false
    hostname: broker
    image: confluentinc/cp-kafka:7.2.2
    ports:
      - ${DATAHUB_MAPPED_KAFKA_BROKER_PORT:-9092}:9092
  datahub-actions:
    depends_on:
      - datahub-gms
    environment:
      - DATAHUB_GMS_PROTOCOL=http
      - DATAHUB_GMS_HOST=datahub-gms
      - DATAHUB_GMS_PORT=8080
      - KAFKA_BOOTSTRAP_SERVER=broker:29092
      - SCHEMA_REGISTRY_URL=http://schema-registry:8081
      - METADATA_AUDIT_EVENT_NAME=MetadataAuditEvent_v4
      - METADATA_CHANGE_LOG_VERSIONED_TOPIC_NAME=MetadataChangeLog_Versioned_v1
      - DATAHUB_SYSTEM_CLIENT_ID=__datahub_system
      - DATAHUB_SYSTEM_CLIENT_SECRET=JohnSnowKnowsNothing
      - KAFKA_PROPERTIES_SECURITY_PROTOCOL=PLAINTEXT
    hostname: actions
    image: acryldata/datahub-actions:${ACTIONS_VERSION:-head}
    restart: on-failure:5
  datahub-frontend-react:
    container_name: datahub-frontend-react
    depends_on:
      - datahub-gms
    environment:
      - DATAHUB_GMS_HOST=datahub-gms
      - DATAHUB_GMS_PORT=8080
      - DATAHUB_SECRET=YouKnowNothing
      - DATAHUB_APP_VERSION=1.0
      - DATAHUB_PLAY_MEM_BUFFER_SIZE=10MB
      - JAVA_OPTS=-Xms512m -Xmx512m -Dhttp.port=9002 -Dconfig.file=datahub-frontend/conf/application.conf -Djava.security.auth.login.config=datahub-frontend/conf/jaas.conf -Dlogback.configurationFile=datahub-frontend/conf/logback.xml -Dlogback.debug=false -Dpidfile.path=/dev/null
      - KAFKA_BOOTSTRAP_SERVER=broker:29092
      - DATAHUB_TRACKING_TOPIC=DataHubUsageEvent_v1
      - ELASTIC_CLIENT_HOST=elasticsearch
      - ELASTIC_CLIENT_PORT=9200
    hostname: datahub-frontend-react
    image: ${DATAHUB_FRONTEND_IMAGE:-linkedin/datahub-frontend-react}:${DATAHUB_VERSION:-head}
    ports:
      - ${DATAHUB_MAPPED_FRONTEND_PORT:-9002}:9002
    volumes:
      - ${HOME}/.datahub/plugins:/etc/datahub/plugins
  datahub-gms:
    container_name: datahub-gms
    depends_on:
      - mysql
    environment:
      - ENTITY_REGISTRY_CONFIG_PATH=/datahub/datahub-gms/resources/entity-registry.yml
      - EBEAN_DATASOURCE_URL=jdbc:mysql://mysql:3306/datahub?verifyServerCertificate=false&useSSL=true&useUnicode=yes&characterEncoding=UTF-8
      - ES_BULK_REFRESH_POLICY=WAIT_UNTIL
      - UI_INGESTION_ENABLED=true
      - ELASTICSEARCH_INDEX_BUILDER_MAPPINGS_REINDEX=true
      - GRAPH_SERVICE_IMPL=elasticsearch
      - DATAHUB_TELEMETRY_ENABLED=${DATAHUB_TELEMETRY_ENABLED:-true}
      - MCE_CONSUMER_ENABLED=true
      - GRAPH_SERVICE_DIFF_MODE_ENABLED=true
      - DATAHUB_SERVER_TYPE=${DATAHUB_SERVER_TYPE:-quickstart}
      - KAFKA_SCHEMAREGISTRY_URL=http://schema-registry:8081
      - MAE_CONSUMER_ENABLED=true
      - JAVA_OPTS=-Xms1g -Xmx1g
      - EBEAN_DATASOURCE_HOST=mysql:3306
      - KAFKA_BOOTSTRAP_SERVER=broker:29092
      - ENTITY_SERVICE_ENABLE_RETENTION=true
      - EBEAN_DATASOURCE_USERNAME=datahub
      - ELASTICSEARCH_INDEX_BUILDER_SETTINGS_REINDEX=true
      - ELASTICSEARCH_PORT=9200
      - ELASTICSEARCH_HOST=elasticsearch
      - PE_CONSUMER_ENABLED=true
      - EBEAN_DATASOURCE_PASSWORD=datahub
      - EBEAN_DATASOURCE_DRIVER=com.mysql.jdbc.Driver
    hostname: datahub-gms
    image: ${DATAHUB_GMS_IMAGE:-linkedin/datahub-gms}:${DATAHUB_VERSION:-head}
    ports:
      - ${DATAHUB_MAPPED_GMS_PORT:-8080}:8080
    volumes:
      - ${HOME}/.datahub/plugins:/etc/datahub/plugins
  elasticsearch:
    container_name: elasticsearch
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - ES_JAVA_OPTS=-Xms256m -Xmx256m -Dlog4j2.formatMsgNoLookups=true
    healthcheck:
      retries: 4
      start_period: 2m
      test:
        - CMD-SHELL
        - curl -sS --fail 'http://localhost:9200/_cluster/health?wait_for_status=yellow&timeout=0s' || exit 1
    hostname: elasticsearch
    image: elasticsearch:7.9.3
    mem_limit: 1g
    ports:
      - ${DATAHUB_MAPPED_ELASTIC_PORT:-9200}:9200
    volumes:
      - esdata:/usr/share/elasticsearch/data
  elasticsearch-setup:
    container_name: elasticsearch-setup
    depends_on:
      - elasticsearch
    environment:
      - ELASTICSEARCH_HOST=elasticsearch
      - ELASTICSEARCH_PORT=9200
      - ELASTICSEARCH_PROTOCOL=http
    hostname: elasticsearch-setup
    image: ${DATAHUB_ELASTIC_SETUP_IMAGE:-linkedin/datahub-elasticsearch-setup}:${DATAHUB_VERSION:-head}
  mysql:
    command: --character-set-server=utf8mb4 --collation-server=utf8mb4_bin --default-authentication-plugin=mysql_native_password
    container_name: mysql
    environment:
      - MYSQL_DATABASE=datahub
      - MYSQL_USER=datahub
      - MYSQL_PASSWORD=datahub
      - MYSQL_ROOT_PASSWORD=datahub
    hostname: mysql
    image: mysql:5.7
    ports:
      - ${DATAHUB_MAPPED_MYSQL_PORT:-3306}:3306
    volumes:
      - ../mysql/init.sql:/docker-entrypoint-initdb.d/init.sql
      - mysqldata:/var/lib/mysql
  mysql-setup:
    container_name: mysql-setup
    depends_on:
      - mysql
    environment:
      - MYSQL_HOST=mysql
      - MYSQL_PORT=3306
      - MYSQL_USERNAME=datahub
      - MYSQL_PASSWORD=datahub
      - DATAHUB_DB_NAME=datahub
    hostname: mysql-setup
    image: acryldata/datahub-mysql-setup:${DATAHUB_VERSION:-head}
  schema-registry:
    container_name: schema-registry
    depends_on:
      - broker
    environment:
      - SCHEMA_REGISTRY_HOST_NAME=schemaregistry
      - SCHEMA_REGISTRY_KAFKASTORE_SECURITY_PROTOCOL=PLAINTEXT
      - SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS=broker:29092
    hostname: schema-registry
    image: confluentinc/cp-schema-registry:7.2.2
    ports:
      - ${DATAHUB_MAPPED_SCHEMA_REGISTRY_PORT:-8081}:8081
  zookeeper:
    container_name: zookeeper
    environment:
      - ZOOKEEPER_CLIENT_PORT=2181
      - ZOOKEEPER_TICK_TIME=2000
    hostname: zookeeper
    image: confluentinc/cp-zookeeper:7.2.2
    ports:
      - ${DATAHUB_MAPPED_ZK_PORT:-2181}:2181
    volumes:
      - zkdata:/var/lib/zookeeper
  nginx:
    build: 
      context: ./nginx
      dockerfile: nginx.Dockerfile
    ports: 
      - 80:80
      - 443:443
    healthcheck:
      test: ['CMD', 'curl', '-f', 'http://localhost:80']
    restart: always

volumes:
  postgres-db:
  hive-data:
  minio-data:
  superset_home:
  redis:
  # elasticsearch_data:
  # mongo_data: 
  esdata: null
  mysqldata: null
  zkdata: null
